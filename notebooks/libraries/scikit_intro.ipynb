{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ddb91d6",
   "metadata": {},
   "source": [
    "# load dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76820d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0                5.1               3.5                1.4               0.2\n",
      "1                4.9               3.0                1.4               0.2\n",
      "2                4.7               3.2                1.3               0.2\n",
      "3                4.6               3.1                1.5               0.2\n",
      "4                5.0               3.6                1.4               0.2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "iris=load_iris()\n",
    "df=pd.DataFrame(iris.data,columns=iris.feature_names)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b502cbf9",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b07d0d",
   "metadata": {},
   "source": [
    "Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe3a2225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2.]\n",
      " [4. 3.]\n",
      " [7. 6.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer #tools to handle missing values\n",
    "import numpy as np\n",
    "data=np.array([[1,2],[np.nan,3],[7,6]])\n",
    "imputer=SimpleImputer(strategy=\"mean\")\n",
    "clean_data=imputer.fit_transform(data)\n",
    "print(clean_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87b57de",
   "metadata": {},
   "source": [
    "Feature scaling (standardisation and Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4092b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.90068117  1.01900435 -1.34022653 -1.3154443 ]\n",
      " [-1.14301691 -0.13197948 -1.34022653 -1.3154443 ]\n",
      " [-1.38535265  0.32841405 -1.39706395 -1.3154443 ]\n",
      " [-1.50652052  0.09821729 -1.2833891  -1.3154443 ]\n",
      " [-1.02184904  1.24920112 -1.34022653 -1.3154443 ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler=StandardScaler()\n",
    "scaled_data=scaler.fit_transform(df)\n",
    "print(scaled_data[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebe8b44",
   "metadata": {},
   "source": [
    "Encoding Categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69e267a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labels = [\"cat\", \"dog\", \"fish\", \"cat\"]\n",
    "encoder=LabelEncoder()\n",
    "encoded_labels=encoder.fit_transform(labels)\n",
    "print(encoded_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bab04a",
   "metadata": {},
   "source": [
    "# Train ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2139ffe7",
   "metadata": {},
   "source": [
    "Linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cd87d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.04471278]\n",
      " [3.06803045]\n",
      " [2.95144208]\n",
      " [3.05054219]\n",
      " [3.00390685]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X=df[['sepal length (cm)']]\n",
    "y=df[['sepal width (cm)']]\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42) #test_size=0.2 means 20% of your data will be used for testing, and the remaining 80% will be used for training.\n",
    "# random state It ensures that every time you run the code, you get the same split of training and testing data.\n",
    "\n",
    "#train model\n",
    "model=LinearRegression()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#predict\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_pred[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec036c7",
   "metadata": {},
   "source": [
    "Classificaton (Logistic regression )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "154a5f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# clf = LogisticRegression()\n",
    "# clf.fit(X_train, y_train)\n",
    "# print(clf.predict(X_test[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ef402b",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58d6df6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# tree = DecisionTreeClassifier()\n",
    "# tree.fit(X_train, y_train)\n",
    "# print(tree.predict(X_test[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5fb48c",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc66e47",
   "metadata": {},
   "source": [
    "check model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75679ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# y_pred = clf.predict(X_test)\n",
    "# print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58f4948",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7b242d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7276f78c",
   "metadata": {},
   "source": [
    "Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "240a734a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# scores = cross_val_score(clf, X, y, cv=5)\n",
    "# print(scores.mean())  # Average accuracy\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exassaro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
